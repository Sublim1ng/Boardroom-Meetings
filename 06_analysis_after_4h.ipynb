{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bae2ec6",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769591b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8654db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/ningyuhan/Desktop/combined_dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d46490",
   "metadata": {},
   "source": [
    "## Tokenize Setence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec56558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text  \n",
    "    # Remove non-ASCII characters directly\n",
    "    text = ''.join([char for char in text if ord(char) < 128])\n",
    "    text = text.strip().lower()  \n",
    "    # Remove all non-alphanumeric characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['Standardized_Sentence'] = df['Sentence'].apply(standardize_text)\n",
    "\n",
    "def standardize_tag(tag):\n",
    "    if pd.isna(tag):\n",
    "        return tag\n",
    "    # Remove all spaces and extra characters\n",
    "    tag = tag.replace(' ', '')\n",
    "    # Ensure consistency in formatting\n",
    "    tag = ','.join(tag.split(','))\n",
    "    return tag\n",
    "\n",
    "df['Tag'] = df['Tag'].apply(standardize_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875e398",
   "metadata": {},
   "source": [
    "## Correct Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070cd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag'] = df['Tag'].apply(\n",
    "    lambda x: x.replace('4h,30]', '4h,03]') if '4h,30]' in x else x\n",
    ")\n",
    "\n",
    "def correct_typo(tag):\n",
    "    parts = tag.strip('[]').split(',')\n",
    "    if len(parts) > 3 and len(parts[3]) == 1:\n",
    "        parts[3] = '0' + parts[3]  \n",
    "    return '[' + ','.join(parts) + ']'\n",
    "\n",
    "df['Tag'] = df['Tag'].apply(correct_typo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ec5c0",
   "metadata": {},
   "source": [
    "# Three Sentence after \"4h\" Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162b23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tag_Component'] = df['Tag'].apply(lambda x: x.split(',')[2] if len(x.split(',')) > 2 else None)\n",
    "\n",
    "# Set the focus category here\n",
    "focus_category = '4h'\n",
    "df['Is_Focus_Category'] = df['Tag_Component'] == focus_category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ef426",
   "metadata": {},
   "source": [
    "## If Meet Consective \"4h\" Sentences, Only Keep the Last One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e052ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_rows_after(df):\n",
    "    relevant_rows = []\n",
    "    in_consecutive_4h = False  # Flag to track if we're in a series of consecutive '4h' tagged rows\n",
    "\n",
    "    for i in range(len(df) - 1):  # Adjusted to avoid index out of range\n",
    "        current_is_4h = df.iloc[i]['Is_Focus_Category']\n",
    "        next_is_4h = df.iloc[i + 1]['Is_Focus_Category']\n",
    "\n",
    "        # If the current row is '4h' and the next row is not, or it's the last '4h' in a series\n",
    "        if current_is_4h and not next_is_4h and in_consecutive_4h:\n",
    "            # Reset the flag since this is the last '4h' in a series\n",
    "            in_consecutive_4h = False\n",
    "            # Add the last '4h' row in the series\n",
    "            relevant_rows.append(df.iloc[i])\n",
    "            # Add the next three non-'4h' rows\n",
    "            for j in range(1, 4):\n",
    "                if i+j >= len(df):  # Check if the index goes beyond the DataFrame\n",
    "                    break\n",
    "                if not df.iloc[i+j]['Is_Focus_Category']:\n",
    "                    relevant_rows.append(df.iloc[i+j])\n",
    "                else:\n",
    "                    break  # Stop if another '4h' tagged row is encountered\n",
    "\n",
    "        # If the current row is '4h' and it's the first in a series or standalone\n",
    "        elif current_is_4h and not in_consecutive_4h:\n",
    "            if not next_is_4h:  # If the next row is not '4h', treat it as a standalone '4h' row\n",
    "                relevant_rows.append(df.iloc[i])\n",
    "                # Add the next three non-'4h' rows\n",
    "                for j in range(1, 4):\n",
    "                    if i+j >= len(df):\n",
    "                        break\n",
    "                    if not df.iloc[i+j]['Is_Focus_Category']:\n",
    "                        relevant_rows.append(df.iloc[i+j])\n",
    "                    else:\n",
    "                        break\n",
    "            else:  # If the next row is also '4h', set the flag and skip this row\n",
    "                in_consecutive_4h = True\n",
    "\n",
    "    return pd.DataFrame(relevant_rows).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5d83978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Standardized_Sentence</th>\n",
       "      <th>Tag_Component</th>\n",
       "      <th>Is_Focus_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[c:13,13,4h,01]</td>\n",
       "      <td>Dodson got mad at Ralph</td>\n",
       "      <td>dodson got mad at ralph</td>\n",
       "      <td>4h</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[c:14,12,2b,01]</td>\n",
       "      <td>The discussion on compensation was most unfort...</td>\n",
       "      <td>the discussion on compensation was most unfort...</td>\n",
       "      <td>2b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[c:15,11,4e2,01]</td>\n",
       "      <td>compensation was most unfortunate.</td>\n",
       "      <td>compensation was most unfortunate</td>\n",
       "      <td>4e2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[c:16,19,4b,01]</td>\n",
       "      <td>Earl wanted full compensation, arguing that th...</td>\n",
       "      <td>earl wanted full compensation arguing that the...</td>\n",
       "      <td>4b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[c:50,02,4h,09]</td>\n",
       "      <td>Everybody talked about the \"armed camp\" atmosp...</td>\n",
       "      <td>everybody talked about the armed camp atmosphe...</td>\n",
       "      <td>4h</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>[c:90,25,4a,06]</td>\n",
       "      <td>and Lyle simply says that he wants to make sur...</td>\n",
       "      <td>and lyle simply says that he wants to make sur...</td>\n",
       "      <td>4a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>[c:101,25,4h,04]</td>\n",
       "      <td>but Lyle says, \"Yes, he was fired.Ó</td>\n",
       "      <td>but lyle says yes he was fired</td>\n",
       "      <td>4h</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>[c:102,22,1b,03]</td>\n",
       "      <td>Laverne says he's holding a meeting to save th...</td>\n",
       "      <td>laverne says hes holding a meeting to save the...</td>\n",
       "      <td>1b</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>[c:103,22,4e3,03]</td>\n",
       "      <td>that includes getting financing to the tune of...</td>\n",
       "      <td>that includes getting financing to the tune of...</td>\n",
       "      <td>4e3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>[c:104,22,4e3,06]</td>\n",
       "      <td>they also need concessions from the workers and</td>\n",
       "      <td>they also need concessions from the workers and</td>\n",
       "      <td>4e3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Tag                                           Sentence  \\\n",
       "12      [c:13,13,4h,01]                            Dodson got mad at Ralph   \n",
       "13      [c:14,12,2b,01]  The discussion on compensation was most unfort...   \n",
       "14     [c:15,11,4e2,01]                 compensation was most unfortunate.   \n",
       "15      [c:16,19,4b,01]  Earl wanted full compensation, arguing that th...   \n",
       "49      [c:50,02,4h,09]  Everybody talked about the \"armed camp\" atmosp...   \n",
       "...                 ...                                                ...   \n",
       "4838    [c:90,25,4a,06]  and Lyle simply says that he wants to make sur...   \n",
       "4849   [c:101,25,4h,04]                but Lyle says, \"Yes, he was fired.Ó   \n",
       "4850   [c:102,22,1b,03]  Laverne says he's holding a meeting to save th...   \n",
       "4851  [c:103,22,4e3,03]  that includes getting financing to the tune of...   \n",
       "4852  [c:104,22,4e3,06]    they also need concessions from the workers and   \n",
       "\n",
       "                                  Standardized_Sentence Tag_Component  \\\n",
       "12                              dodson got mad at ralph            4h   \n",
       "13    the discussion on compensation was most unfort...            2b   \n",
       "14                    compensation was most unfortunate           4e2   \n",
       "15    earl wanted full compensation arguing that the...            4b   \n",
       "49    everybody talked about the armed camp atmosphe...            4h   \n",
       "...                                                 ...           ...   \n",
       "4838  and lyle simply says that he wants to make sur...            4a   \n",
       "4849                     but lyle says yes he was fired            4h   \n",
       "4850  laverne says hes holding a meeting to save the...            1b   \n",
       "4851  that includes getting financing to the tune of...           4e3   \n",
       "4852    they also need concessions from the workers and           4e3   \n",
       "\n",
       "      Is_Focus_Category  \n",
       "12                 True  \n",
       "13                False  \n",
       "14                False  \n",
       "15                False  \n",
       "49                 True  \n",
       "...                 ...  \n",
       "4838              False  \n",
       "4849               True  \n",
       "4850              False  \n",
       "4851              False  \n",
       "4852              False  \n",
       "\n",
       "[980 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_after = get_relevant_rows_after(df)\n",
    "df_after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0799e503",
   "metadata": {},
   "source": [
    "# Topics after \"4h\" Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e8f0f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_codes = {\n",
    "    '01': 'Routine Board Functions',\n",
    "    '02': 'Scope of Board Issues',\n",
    "    '03': 'Financial Status of Firm',\n",
    "    '04': 'Management Personnel Issues',\n",
    "    '05': 'Marketing and Sales',\n",
    "    '06': 'Employee Stock Ownership Plan (ESOP) Financial',\n",
    "    '07': 'ESOP Participation',\n",
    "    '08': 'Employee Benefits',\n",
    "    '09': 'Plant Production and Manufacturing Process Issues',\n",
    "    '10': 'The Union and Contract Issues',\n",
    "    '11': 'Supervision',\n",
    "    '12': 'hog procurement',\n",
    "    '13': 'Political Relations with the Community'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd9010",
   "metadata": {},
   "source": [
    "## Topic Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dbc918e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Financial Status of Firm: 196 times (20.0%)\n",
      "Management Personnel Issues: 181 times (18.47%)\n",
      "The Union and Contract Issues: 135 times (13.78%)\n",
      "Routine Board Functions: 99 times (10.1%)\n",
      "Plant Production and Manufacturing Process Issues: 83 times (8.47%)\n",
      "ESOP Participation: 78 times (7.96%)\n",
      "Marketing and Sales: 62 times (6.33%)\n",
      "Employee Benefits: 50 times (5.1%)\n",
      "Employee Stock Ownership Plan (ESOP) Financial: 47 times (4.8%)\n",
      "Supervision: 24 times (2.45%)\n",
      "hog procurement: 16 times (1.63%)\n",
      "Political Relations with the Community: 6 times (0.61%)\n",
      "Scope of Board Issues: 3 times (0.31%)\n"
     ]
    }
   ],
   "source": [
    "# Extract the fourth component (Topic) from the 'Tag' field\n",
    "df_after['Topic_Component'] = df_after['Tag'].apply(\n",
    "    lambda x: x.split(',')[3].strip(']').strip() if len(x.split(',')) > 3 else None\n",
    ")\n",
    "\n",
    "# Filter the DataFrame for rows where 'Is_Focus_Category' is True\n",
    "df_focus_true = df_after[df_after['Is_Focus_Category']]\n",
    "\n",
    "# Count the occurrences of each unique 'Topic_Component' in these rows\n",
    "topic_component_counts = df_after['Topic_Component'].value_counts()\n",
    "\n",
    "# Translate the topic components using the topic_codes dictionary\n",
    "translated_topic_counts = {topic_codes.get(key, \"Unknown\"): value for key, value in topic_component_counts.items()}\n",
    "\n",
    "# Display the translated counts\n",
    "translated_topic_counts\n",
    "\n",
    "# Calculate the total count for percentage calculation\n",
    "total_count = topic_component_counts.sum()\n",
    "\n",
    "# Translate the topic components and calculate the percentage\n",
    "translated_topic_counts = {\n",
    "  topic_codes.get(key, \"Unknown\"): {\n",
    "    'Count': value, \n",
    "    'Percentage': (value / total_count) * 100\n",
    "  }\n",
    "  for key, value in topic_component_counts.items() \n",
    "}\n",
    "\n",
    "for topic, data in translated_topic_counts.items():\n",
    "  percentage = round(data['Percentage'], 2)\n",
    "  data['Percentage'] = f\"{percentage}%\"\n",
    "\n",
    "for topic, data in translated_topic_counts.items():\n",
    "  print(f\"{topic}: {data['Count']} times ({data['Percentage']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d4302",
   "metadata": {},
   "source": [
    "## Topic Sequence after \"4h\" Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c896d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Sequences Following Focus Topic (Translated):\n",
      "('Financial Status of Firm',): 42 times (29.58%)\n",
      "('Management Personnel Issues',): 34 times (23.94%)\n",
      "('Routine Board Functions',): 23 times (16.2%)\n",
      "('The Union and Contract Issues',): 14 times (9.86%)\n",
      "('Plant Production and Manufacturing Process Issues',): 12 times (8.45%)\n",
      "('ESOP Participation',): 10 times (7.04%)\n",
      "('Employee Stock Ownership Plan (ESOP) Financial',): 7 times (4.93%)\n"
     ]
    }
   ],
   "source": [
    "sequences_following_focus_topic = []\n",
    "\n",
    "for index in range(len(df_after)):\n",
    "    if df_after.iloc[index]['Is_Focus_Category']:\n",
    "        topic_sequence = []\n",
    "        # Look ahead for the next three non-'4h' rows\n",
    "        for j in range(1, 4):  # Start from the next row\n",
    "            if index + j >= len(df_after):  # Check if the index goes beyond the DataFrame\n",
    "                break\n",
    "            if not df_after.iloc[index + j]['Is_Focus_Category']:\n",
    "                topic_sequence.append(df_after.iloc[index + j]['Topic_Component'])\n",
    "        sequences_following_focus_topic.append(tuple(topic_sequence))  # No need to reverse\n",
    "\n",
    "sequence_counts = Counter(sequences_following_focus_topic)\n",
    "top10_sequences = sequence_counts.most_common(10)\n",
    "\n",
    "# Consolidate duplicates\n",
    "consolidated_counts = {}\n",
    "for seq, count in top10_sequences:\n",
    "    consolidated_seq = tuple(set(seq))  # Remove duplicate topics within the sequence\n",
    "    if consolidated_seq not in consolidated_counts:\n",
    "        consolidated_counts[consolidated_seq] = 0\n",
    "    consolidated_counts[consolidated_seq] += count\n",
    "\n",
    "# Translate codes\n",
    "translated_counts = {}\n",
    "for seq, count in consolidated_counts.items():\n",
    "    translated_seq = tuple(topic_codes.get(code, 'Unknown') for code in seq)  \n",
    "    if translated_seq not in translated_counts:\n",
    "        translated_counts[translated_seq] = 0\n",
    "    translated_counts[translated_seq] += count\n",
    "\n",
    "# Get total count\n",
    "total_count = sum(count for seq, count in top10_sequences)\n",
    "\n",
    "# Print results with percentage\n",
    "print(\"Top Sequences Following Focus Topic (Translated):\")\n",
    "for translated_seq, count in translated_counts.items():\n",
    "    percentage = round(count / total_count * 100, 2)\n",
    "    print(f\"{translated_seq}: {count} times ({percentage}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146d313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('03', '03', '03'), 30),\n",
       " (('04', '04', '04'), 25),\n",
       " (('01', '01', '01'), 16),\n",
       " (('10', '10', '10'), 14),\n",
       " (('09', '09', '09'), 12),\n",
       " (('03', '03'), 12),\n",
       " (('07', '07', '07'), 10),\n",
       " (('04', '04'), 9),\n",
       " (('01', '01'), 7),\n",
       " (('06', '06', '06'), 7)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7cc4c9",
   "metadata": {},
   "source": [
    "# Verbal Contribution after \"4h\" Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4de9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbal_contribution_codes = {\n",
    "    '1': 'Initiation activity',\n",
    "    '1a': 'Motion making',\n",
    "    '1b': 'Information giving',\n",
    "    '1c': 'Information seeking',\n",
    "    '1d': 'Making specific suggestions for action',\n",
    "    '2': 'Support behavior',\n",
    "    '2a': 'Motion seconding',\n",
    "    '2b': 'Making statements in support of another person\\'s argument',\n",
    "    '3': 'System maintenance',\n",
    "    '3a': 'Tension management',\n",
    "    '3b': 'Direction of traffic',\n",
    "    '3c': 'Collective spirit and solidarity moves',\n",
    "    '4': 'Board discussion, debate, argumentation',\n",
    "    '4a': 'Personal defensiveness',\n",
    "    '4b': 'Personal gains',\n",
    "    '4c': 'Agreeing reluctantly',\n",
    "    '4d': 'Sensible,nonpersonal arguments',\n",
    "    '4e1': 'Management',\n",
    "    '4e2': 'Union',\n",
    "    '4e3': 'People (workers) as distinct from union or the union leadership',\n",
    "    '4f': 'Attempts to propose new board topics',\n",
    "    '4g': 'Corporate interests',\n",
    "    '4h': 'Disagreements, conflicts, attacks',\n",
    "    '4i': 'Stonewalling',\n",
    "    '5': 'Unclassified verbal behaviors',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d75e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1c -> 1b -> 4d] follows 4h 5 times.\n",
      "[1a -> 2a -> 1b] follows 4h 4 times.\n",
      "[4d -> 4d -> 1b] follows 4h 4 times.\n",
      "[1b -> 4d -> 1c] follows 4h 4 times.\n",
      "[1c -> 1b -> 1b] follows 4h 4 times.\n",
      "[4e2 -> 1c] follows 4h 3 times.\n",
      "[4d -> 1c -> 4d] follows 4h 3 times.\n",
      "[4d -> 4d -> 4d] follows 4h 3 times.\n",
      "[4a -> 4a] follows 4h 3 times.\n",
      "[4a -> 4d] follows 4h 3 times.\n"
     ]
    }
   ],
   "source": [
    "def get_following_rows(df):\n",
    "    following_rows = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['Is_Focus_Category']:\n",
    "            sequence = []\n",
    "            # Look ahead for the next three non-'4h' rows\n",
    "            for j in range(1, 4):\n",
    "                if i+j >= len(df):\n",
    "                    break\n",
    "                if not df.iloc[i+j]['Is_Focus_Category']:\n",
    "                    sequence.append(df.iloc[i+j]['Tag_Component'])\n",
    "            following_rows.append(tuple(sequence))\n",
    "\n",
    "    return following_rows\n",
    "\n",
    "# Analyze sequences following the '4h' instances\n",
    "sequences_following_focus = get_following_rows(df_after)\n",
    "\n",
    "# Count the frequency of each sequence\n",
    "sequence_counts = Counter(sequences_following_focus)\n",
    "top10_sequences = sequence_counts.most_common(10)\n",
    "\n",
    "# Format the results\n",
    "formatted_results = []\n",
    "for sequence, count in top10_sequences:\n",
    "    sequence_str = ' -> '.join(sequence)\n",
    "    sentence = f\"[{sequence_str}] follows {focus_category} {count} times.\"\n",
    "    formatted_results.append(sentence)\n",
    "\n",
    "# Print formatted results\n",
    "for result in formatted_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a990221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "print(df_after['Is_Focus_Category'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d3010",
   "metadata": {},
   "source": [
    "## Category 3 after \"4h\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "383ac5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1c', '4e1', '3a'),\n",
       " ('3a', '4a', '1c'),\n",
       " ('3a', '4d'),\n",
       " ('4d', '4d', '3b'),\n",
       " ('4d', '3b', '1c'),\n",
       " ('4i', '3a'),\n",
       " ('3a', '4a', '3a'),\n",
       " ('3a', '4a'),\n",
       " ('4a', '3a'),\n",
       " ('3a', '1d', '4c'),\n",
       " ('05', '3a', '1c'),\n",
       " ('1b', '1b', '3a'),\n",
       " ('1b', '3a', '3a'),\n",
       " ('1b', '4d', '3a'),\n",
       " ('4i', '3b', '1d'),\n",
       " ('4g', '3a', '1c'),\n",
       " ('4a', '3b'),\n",
       " ('3b', '1b', '1b'),\n",
       " ('3a', '4e2', '4e1'),\n",
       " ('3a', '4i', '1d'),\n",
       " ('3a', '4c', '1b'),\n",
       " ('1b', '1c', '3a'),\n",
       " ('05', '3b'),\n",
       " ('05', '05', '3b'),\n",
       " ('3a', '4e2', '1c'),\n",
       " ('1c', '4d', '3b'),\n",
       " ('3a', '1b', '4d'),\n",
       " ('3b', '1b'),\n",
       " ('4g', '3b', '3b'),\n",
       " ('4d', '1b', '3a'),\n",
       " ('3a', '4e2'),\n",
       " ('4a', '3b', '1b'),\n",
       " ('3a', '3a', '4g'),\n",
       " ('3b', '1c', '4d'),\n",
       " ('1b', '3b', '2b'),\n",
       " ('3b', '4e1'),\n",
       " ('4d', '3a'),\n",
       " ('3a', '3b', '3b'),\n",
       " ('4d', '3b', '4d'),\n",
       " ('4i', '3a', '4e1'),\n",
       " ('3b', '4c', '1b'),\n",
       " ('4b', '05', '3b'),\n",
       " ('1a', '2a', '3b'),\n",
       " ('4d', '3b', '4c'),\n",
       " ('3a', '4d', '1d'),\n",
       " ('4e2', '4d', '3a'),\n",
       " ('3b', '1c', '4d'),\n",
       " ('3a', '1c', '3b'),\n",
       " ('3b', '4f', '1c'),\n",
       " ('1b', '3b'),\n",
       " ('3b', '4e2'),\n",
       " ('4c', '3a', '1a'),\n",
       " ('3a', '1b'),\n",
       " ('4a', '3a'),\n",
       " ('3a', '4i', '1c'),\n",
       " ('4d', '3a', '4a'),\n",
       " ('4d', '3a', '1c'),\n",
       " ('4d', '4d', '3a'),\n",
       " ('1d', '05', '3b'),\n",
       " ('4d', '1b', '3a'),\n",
       " ('3b', '4i')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_with_3a_3b_3c = [seq for seq in sequences_following_focus if any(code in seq for code in [\"3a\", \"3b\", \"3c\"])]\n",
    "print(len(sequences_with_3a_3b_3c))\n",
    "sequences_with_3a_3b_3c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be7fc1",
   "metadata": {},
   "source": [
    "# People Who Speak after \"4h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16860ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Name': ['Chuck Swisher', 'Emmet “Mac” MacGuire', 'Herb Epstein', 'John Lambert', 'Wally Rath, regional sales managers, & Robert Cray & John DeGroat', 'Bob Soleday, Mowry, Bloomfield,(beginning Jan. 1985)', 'Ivan Pihl', 'Art Frye', 'Jack Thomas', 'Harold Rath', 'Ralph Helstein', 'Tove Hammer', 'Len Dodson', 'Sid Oberman', 'Bob Fulton', 'Walter Cunningham', 'Dick Clarke', 'Phyllis Walters', 'Earl Murray', 'Glen Bass', 'Clark Towne', 'LaVerne Patrie', 'Peter Bruskern', 'Bob Kavangh', 'Lyle Taylor', 'Chuck Mueller', 'Gene Redmond & other union officials', 'Jim Miller', 'Ron Peterson, William Scogland, Charles McCarthy, Tom Mandler, Wes Hall, Ravel', 'Berthold', 'Rudnick', 'Gerjerts, Bill Wait', 'Jack Curtis', 'Bruce Wilson', 'John Stevens, Greg Kohn, Lewis Rudel', 'Potential Business deal people', 'ESOP consultants (Chris Meek & Warner Woodworth, W.F. Whyte)', 'ESOP trustees, Larry Wrede, Jim Anderson, Cox', 'Wayne Wright', 'Insurance people & other consultants', 'Leroy Grittman, Tobias, Mary Frost', 'Swisher & Cohrt, Law firm (Steve Weidner)'],\n",
    "    'Id Number': ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44']\n",
    "}\n",
    "\n",
    "person_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae3945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_after['Person_Component'] = df_after['Tag'].apply(\n",
    "    lambda x: x.split(',')[1].strip(']').strip() if len(x.split(',')) > 3 else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4dd2f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12', '11', '19'),\n",
       " ('01', '08'),\n",
       " ('15', '08', '15'),\n",
       " ('15', '04'),\n",
       " ('04', '04', '04'),\n",
       " ('02', '04', '12'),\n",
       " ('20', '04', '12'),\n",
       " ('01', '02'),\n",
       " ('02', '02', '15'),\n",
       " ('19', '02', '20'),\n",
       " ('11', '02', '04'),\n",
       " ('20', '02', '20'),\n",
       " ('11', '02', '01'),\n",
       " ('12', '01', '01'),\n",
       " ('12', '02'),\n",
       " ('02', '01'),\n",
       " ('01', '02', '11'),\n",
       " ('01', '37'),\n",
       " ('12', '04'),\n",
       " ('04', '01'),\n",
       " ('01', '11', '37'),\n",
       " ('25', '25', '25'),\n",
       " ('08', '02', '08'),\n",
       " ('25', '12'),\n",
       " ('12', '08', '19'),\n",
       " ('11', '01', '01'),\n",
       " ('09', '08', '02'),\n",
       " ('20', '08', '20'),\n",
       " ('37', '08', '11'),\n",
       " ('08', '02'),\n",
       " ('02', '26', '11'),\n",
       " ('01', '25'),\n",
       " ('25', '25', '01'),\n",
       " ('12', '02', '11'),\n",
       " ('12', '02', '17'),\n",
       " ('11', '01', '20'),\n",
       " ('15', '18', '02'),\n",
       " ('10', '01', '01'),\n",
       " ('04', '20'),\n",
       " ('20', '09', '11'),\n",
       " ('04', '20', '04'),\n",
       " ('02', '02'),\n",
       " ('20', '12', '01'),\n",
       " ('04', '15', '15'),\n",
       " ('13', '01', '12'),\n",
       " ('14', '09', '08'),\n",
       " ('09', '03', '03'),\n",
       " ('03', '01', '01'),\n",
       " ('04', '12'),\n",
       " ('09', '14', '01'),\n",
       " ('26', '03', '08'),\n",
       " ('26', '26', '03'),\n",
       " ('26', '11', '11'),\n",
       " ('03', '15', '15'),\n",
       " ('15', '03', '14'),\n",
       " ('11', '12', '15'),\n",
       " ('04', '03', '03'),\n",
       " ('03', '01', '12'),\n",
       " ('03', '39', '39'),\n",
       " ('03', '39', '03'),\n",
       " ('01', '01', '25'),\n",
       " ('03', '03', '03'),\n",
       " ('03', '06', '09'),\n",
       " ('25', '25', '03'),\n",
       " ('14', '14'),\n",
       " ('14', '25', '06'),\n",
       " ('01', '12'),\n",
       " ('01', '25'),\n",
       " ('25', '19'),\n",
       " ('03', '13', '03'),\n",
       " ('11', '01', '09'),\n",
       " ('09', '25', '25'),\n",
       " ('03', '03'),\n",
       " ('03', '03'),\n",
       " ('03', '02', '09'),\n",
       " ('01', '25', '03'),\n",
       " ('03', '08', '03'),\n",
       " ('03', '01'),\n",
       " ('01', '01', '11'),\n",
       " ('01', '25', '25'),\n",
       " ('03', '01', '04'),\n",
       " ('03', '03', '19'),\n",
       " ('12', '12', '03'),\n",
       " ('15', '03', '12'),\n",
       " ('03', '25', '03'),\n",
       " ('25', '19', '06'),\n",
       " ('03', '25', '03'),\n",
       " ('04', '25', '14'),\n",
       " ('15', '20'),\n",
       " ('25', '01', '01'),\n",
       " ('15', '03'),\n",
       " ('15', '11', '01'),\n",
       " ('39', '17', '15'),\n",
       " ('03', '03', '11'),\n",
       " ('25', '14', '02'),\n",
       " ('25', '14', '02'),\n",
       " ('03', '15'),\n",
       " ('11', '15', '12'),\n",
       " ('03', '25', '12'),\n",
       " ('11', '11', '01'),\n",
       " ('01', '25', '12'),\n",
       " ('04', '04', '25'),\n",
       " ('25', '04', '03'),\n",
       " ('03', '04', '03'),\n",
       " ('03', '04', '04'),\n",
       " ('25', '04', '09'),\n",
       " ('01', '01', '08'),\n",
       " ('12', '03', '03'),\n",
       " ('12', '15', '17'),\n",
       " ('14', '25', '25'),\n",
       " ('25', '03'),\n",
       " ('03', '03', '03'),\n",
       " ('03', '14'),\n",
       " ('19', '08'),\n",
       " ('08', '25'),\n",
       " ('14', '08', '13'),\n",
       " ('04', '04', '11'),\n",
       " ('11', '08', '11'),\n",
       " ('08', '13', '13'),\n",
       " ('08', '19'),\n",
       " ('12', '18'),\n",
       " ('18', '19', '25'),\n",
       " ('13', '12', '11'),\n",
       " ('14', '08'),\n",
       " ('03', '12', '12'),\n",
       " ('03', '06', '09'),\n",
       " ('01', '11'),\n",
       " ('04', '25', '11'),\n",
       " ('03', '01', '01'),\n",
       " ('01', '01', '01'),\n",
       " ('25', '01'),\n",
       " ('25', '25', '01'),\n",
       " ('01', '14', '11'),\n",
       " ('01', '01', '14'),\n",
       " ('01', '20', '20'),\n",
       " ('08', '15', '15'),\n",
       " ('01', '01', '03'),\n",
       " ('11', '15', '05'),\n",
       " ('03', '44', '03'),\n",
       " ('25', '14'),\n",
       " ('03', '01'),\n",
       " ('25', '12'),\n",
       " ('12', '31', '08'),\n",
       " ('11', '18'),\n",
       " ('18', '03', '01'),\n",
       " ('11', '01'),\n",
       " ('01', '31'),\n",
       " ('31', '11'),\n",
       " ('11', '11', '01'),\n",
       " ('03', '08'),\n",
       " ('08', '03'),\n",
       " ('03', '03'),\n",
       " ('01', '25', '11'),\n",
       " ('03', '17', '03'),\n",
       " ('03', '11', '03'),\n",
       " ('03', '01', '12'),\n",
       " ('19', '12', '03'),\n",
       " ('12', '20', '03'),\n",
       " ('01', '12', '25'),\n",
       " ('03', '03', '12'),\n",
       " ('06', '12', '20'),\n",
       " ('01', '01', '25'),\n",
       " ('25', '06', '06'),\n",
       " ('03', '03'),\n",
       " ('14', '19', '12'),\n",
       " ('31', '08', '12'),\n",
       " ('03', '03', '03'),\n",
       " ('14', '03', '02'),\n",
       " ('02', '03', '15'),\n",
       " ('15', '03', '14'),\n",
       " ('02', '02', '03'),\n",
       " ('03', '03', '02'),\n",
       " ('03', '11'),\n",
       " ('11', '03'),\n",
       " ('03', '06', '03'),\n",
       " ('14', '11', '06'),\n",
       " ('11', '15', '13'),\n",
       " ('17', '06', '12'),\n",
       " ('03', '03', '03'),\n",
       " ('03', '08'),\n",
       " ('08', '12', '03'),\n",
       " ('15', '17', '01'),\n",
       " ('03', '03', '30'),\n",
       " ('06', '25', '03'),\n",
       " ('19', '05', '05'),\n",
       " ('01', '03', '03'),\n",
       " ('11', '17', '11'),\n",
       " ('17', '01', '01'),\n",
       " ('20', '18', '19'),\n",
       " ('16', '20', '13'),\n",
       " ('03', '12', '17'),\n",
       " ('01', '01', '30'),\n",
       " ('03', '01', '01'),\n",
       " ('30', '30', '17'),\n",
       " ('11', '03', '03'),\n",
       " ('17', '15', '17'),\n",
       " ('19', '19', '18'),\n",
       " ('01', '12', '01'),\n",
       " ('20', '02', '25'),\n",
       " ('20', '11', '25'),\n",
       " ('31', '11'),\n",
       " ('11', '19'),\n",
       " ('12', '14', '12'),\n",
       " ('12', '01', '01'),\n",
       " ('01', '20', '01'),\n",
       " ('20', '14'),\n",
       " ('25', '01', '08'),\n",
       " ('06', '12', '08'),\n",
       " ('08', '01', '33'),\n",
       " ('15', '13', '25'),\n",
       " ('12', '25', '25'),\n",
       " ('01', '25'),\n",
       " ('25', '21', '21'),\n",
       " ('12', '25'),\n",
       " ('25', '14', '25'),\n",
       " ('21', '21', '01'),\n",
       " ('21', '01', '21'),\n",
       " ('21', '12', '12'),\n",
       " ('14', '25', '25'),\n",
       " ('12', '25', '15'),\n",
       " ('01', '15'),\n",
       " ('15', '08', '20'),\n",
       " ('20', '20'),\n",
       " ('20', '01'),\n",
       " ('14', '18', '21'),\n",
       " ('18', '12', '18'),\n",
       " ('01', '01', '01'),\n",
       " ('12', '06', '25'),\n",
       " ('12', '12', '13'),\n",
       " ('20', '38', '38'),\n",
       " ('25', '12', '25'),\n",
       " ('40', '40'),\n",
       " ('40', '40', '40'),\n",
       " ('15', '25', '12'),\n",
       " ('12', '12', '22'),\n",
       " ('15', '12', '25'),\n",
       " ('25', '25'),\n",
       " ('22', '25', '22'),\n",
       " ('15', '13', '08'),\n",
       " ('43', '08', '43'),\n",
       " ('06', '12', '12'),\n",
       " ('43', '20', '43'),\n",
       " ('12', '20', '12'),\n",
       " ('22', '20'),\n",
       " ('20', '12', '12'),\n",
       " ('06', '06'),\n",
       " ('06', '25', '25'),\n",
       " ('25', '25', '25'),\n",
       " ('15', '15', '24'),\n",
       " ('12', '22', '20'),\n",
       " ('31', '31'),\n",
       " ('31', '08', '13'),\n",
       " ('24', '20', '20'),\n",
       " ('15', '22', '15'),\n",
       " ('22', '20', '15'),\n",
       " ('25', '25', '25'),\n",
       " ('22', '25'),\n",
       " ('25', '13', '12'),\n",
       " ('25', '25', '25'),\n",
       " ('15', '25'),\n",
       " ('20', '25'),\n",
       " ('15', '31', '31'),\n",
       " ('25', '25', '12'),\n",
       " ('15', '12', '13'),\n",
       " ('25', '25', '25'),\n",
       " ('25', '25', '25'),\n",
       " ('12', '25', '12'),\n",
       " ('25', '25'),\n",
       " ('25', '15', '25'),\n",
       " ('22', '22', '22')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_following_focus_person = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for index in range(len(df_after) - 1):  \n",
    "    # Check if the current row is tagged with '4h'\n",
    "    if df_after.iloc[index]['Is_Focus_Category']:\n",
    "        person_sequence = []\n",
    "        # Look ahead to the next three rows, provided they exist and are not tagged as '4h'\n",
    "        for j in range(1, 4):\n",
    "            if index + j < len(df_after) and not df_after.iloc[index + j]['Is_Focus_Category']:\n",
    "                person_sequence.append(df_after.iloc[index + j]['Person_Component'])\n",
    "        # Append the sequence, if any, to the list\n",
    "        if person_sequence:\n",
    "            sequences_following_focus_person.append(tuple(person_sequence))\n",
    "\n",
    "sequences_following_focus_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d53d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>Tove Hammer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>Ralph Helstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>Earl Murray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>89</td>\n",
       "      <td>Chuck Swisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>34</td>\n",
       "      <td>Art Frye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>43</td>\n",
       "      <td>Bob Fulton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04</td>\n",
       "      <td>27</td>\n",
       "      <td>John Lambert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02</td>\n",
       "      <td>29</td>\n",
       "      <td>Emmet “Mac” MacGuire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>Glen Bass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>John Stevens, Greg Kohn, Lewis Rudel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "      <td>Lyle Taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>09</td>\n",
       "      <td>11</td>\n",
       "      <td>Jack Thomas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>Chuck Mueller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>Dick Clarke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>Phyllis Walters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Harold Rath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Len Dodson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "      <td>Sid Oberman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>03</td>\n",
       "      <td>104</td>\n",
       "      <td>Herb Epstein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>ESOP consultants (Chris Meek &amp; Warner Woodwort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>06</td>\n",
       "      <td>17</td>\n",
       "      <td>Bob Soleday, Mowry, Bloomfield,(beginning Jan....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>05</td>\n",
       "      <td>3</td>\n",
       "      <td>Wally Rath, regional sales managers, &amp; Robert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>Swisher &amp; Cohrt, Law firm (Steve Weidner)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>Ron Peterson, William Scogland, Charles McCart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>Jim Miller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Walter Cunningham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>Rudnick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>Clark Towne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>Potential Business deal people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>ESOP trustees, Larry Wrede, Jim Anderson, Cox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>LaVerne Patrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>Leroy Grittman, Tobias, Mary Frost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>Bob Kavangh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Count                                               Name\n",
       "0   12     72                                        Tove Hammer\n",
       "1   11     46                                     Ralph Helstein\n",
       "2   19     16                                        Earl Murray\n",
       "3   01     89                                      Chuck Swisher\n",
       "4   08     34                                           Art Frye\n",
       "5   15     43                                         Bob Fulton\n",
       "6   04     27                                       John Lambert\n",
       "7   02     29                               Emmet “Mac” MacGuire\n",
       "8   20     36                                          Glen Bass\n",
       "9   37      3               John Stevens, Greg Kohn, Lewis Rudel\n",
       "10  25     96                                        Lyle Taylor\n",
       "11  09     11                                        Jack Thomas\n",
       "12  26      5                                      Chuck Mueller\n",
       "13  17     12                                        Dick Clarke\n",
       "14  18     10                                    Phyllis Walters\n",
       "15  10      1                                        Harold Rath\n",
       "16  13     14                                         Len Dodson\n",
       "17  14     25                                        Sid Oberman\n",
       "18  03    104                                       Herb Epstein\n",
       "19  39      4  ESOP consultants (Chris Meek & Warner Woodwort...\n",
       "20  06     17  Bob Soleday, Mowry, Bloomfield,(beginning Jan....\n",
       "21  05      3  Wally Rath, regional sales managers, & Robert ...\n",
       "22  44      1          Swisher & Cohrt, Law firm (Steve Weidner)\n",
       "23  31     10  Ron Peterson, William Scogland, Charles McCart...\n",
       "24  30      4                                         Jim Miller\n",
       "25  16      1                                  Walter Cunningham\n",
       "26  33      1                                            Rudnick\n",
       "27  21      8                                        Clark Towne\n",
       "28  38      2                     Potential Business deal people\n",
       "29  40      5      ESOP trustees, Larry Wrede, Jim Anderson, Cox\n",
       "30  22     11                                     LaVerne Patrie\n",
       "31  43      4                 Leroy Grittman, Tobias, Mary Frost\n",
       "32  24      2                                        Bob Kavangh"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the list of tuples to count each id\n",
    "flattened_ids = [id for sequence in sequences_following_focus_person for id in sequence]\n",
    "\n",
    "# Count each id\n",
    "id_counts = Counter(flattened_ids)\n",
    "\n",
    "# Convert the counter object to a DataFrame\n",
    "df_id_counts = pd.DataFrame(id_counts.items(), columns=['ID', 'Count'])\n",
    "\n",
    "# Merge the count DataFrame with the translation DataFrame\n",
    "merged_df = pd.merge(df_id_counts, person_df, left_on='ID', right_on='Id Number', how='left')\n",
    "\n",
    "# Select only the necessary columns\n",
    "final_df = merged_df[['ID', 'Count', 'Name']]\n",
    "\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "263.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
