{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ac46d5",
   "metadata": {},
   "source": [
    "**In this notebook, I am trying to identify the precursors (3 and 5 sentences before the desired category) that might lead to the '4h' verbal contribution category, which stands for attack, disagreement, and conflict.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439176ef",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57091587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166b8c8",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c5df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[c:01,01,1b,01]</td>\n",
       "      <td>Swisher opens the meeting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c:02,08,1a,01]</td>\n",
       "      <td>It was moved by Mr. Frey,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[c:03,10,2a,01]</td>\n",
       "      <td>seconded by Mr. Rath, that the minutes of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[c:04,02,1b,03]</td>\n",
       "      <td>Mr. McGuire informed the Board that the May st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[c:05,02,4d,03]</td>\n",
       "      <td>He did indicate the preliminary weekly results...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tag                                           Sentence\n",
       "0  [c:01,01,1b,01]                         Swisher opens the meeting.\n",
       "1  [c:02,08,1a,01]                          It was moved by Mr. Frey,\n",
       "2  [c:03,10,2a,01]  seconded by Mr. Rath, that the minutes of the ...\n",
       "3  [c:04,02,1b,03]  Mr. McGuire informed the Board that the May st...\n",
       "4  [c:05,02,4d,03]  He did indicate the preliminary weekly results..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ningyuhan/Desktop/combined_dataframe.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89858a39",
   "metadata": {},
   "source": [
    "# Get 3 tags and sentences before meeting 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcc7be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[c:10,12,2a,04]</td>\n",
       "      <td>seconded by Mrs. Hammer, and unanimously carri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c:11,15,1a,01]</td>\n",
       "      <td>It was moved by Mr. Fulton,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[c:12,11,2a,01]</td>\n",
       "      <td>seconded by Mr. Helstein, and unanimously carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[c:13,13,4h,01]</td>\n",
       "      <td>Dodson got mad at Ralph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[c:47,04,2b,05]</td>\n",
       "      <td>Lambert echoing that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>[c:87,12,4h,06]</td>\n",
       "      <td>Tove gets angry at Lyle and turns on him and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>[c:98,22,4e3,04]</td>\n",
       "      <td>which includes Walker, who is an old CEO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>[c:99,12,1c,04]</td>\n",
       "      <td>I ask if he wasn't the one who was fired and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>[c:100,22,1b,04]</td>\n",
       "      <td>Laverne says he wasnÕt fired,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>[c:101,25,4h,04]</td>\n",
       "      <td>but Lyle says, \"Yes, he was fired.Ó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1027 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag                                           Sentence\n",
       "0      [c:10,12,2a,04]  seconded by Mrs. Hammer, and unanimously carri...\n",
       "1      [c:11,15,1a,01]                        It was moved by Mr. Fulton,\n",
       "2      [c:12,11,2a,01]  seconded by Mr. Helstein, and unanimously carr...\n",
       "3      [c:13,13,4h,01]                            Dodson got mad at Ralph\n",
       "4      [c:47,04,2b,05]                              Lambert echoing that.\n",
       "...                ...                                                ...\n",
       "1022   [c:87,12,4h,06]  Tove gets angry at Lyle and turns on him and s...\n",
       "1023  [c:98,22,4e3,04]          which includes Walker, who is an old CEO.\n",
       "1024   [c:99,12,1c,04]  I ask if he wasn't the one who was fired and w...\n",
       "1025  [c:100,22,1b,04]                      Laverne says he wasnÕt fired,\n",
       "1026  [c:101,25,4h,04]                but Lyle says, \"Yes, he was fired.Ó\n",
       "\n",
       "[1027 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_sentences_with_4h_and_preceding(df, target_component='4h', num_previous=3):\n",
    "    df['ThirdComponent'] = df['Tag'].apply(lambda x: x.split(',')[2])\n",
    "\n",
    "    included_sentences = set()\n",
    "    result = []\n",
    "\n",
    "    for index in range(len(df)):\n",
    "        if df.iloc[index]['ThirdComponent'] == target_component:\n",
    "            # Determine the range of indices to include\n",
    "            start_index = max(index - num_previous, 0)\n",
    "            end_index = index + 1  # Include current index\n",
    "\n",
    "            for idx in range(start_index, end_index):\n",
    "                # Check to avoid duplicates\n",
    "                if df.iloc[idx]['Sentence'] not in included_sentences:\n",
    "                    result.append(df.iloc[idx][['Tag', 'Sentence']].tolist())\n",
    "                    included_sentences.add(df.iloc[idx]['Sentence'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "result = find_sentences_with_4h_and_preceding(df)\n",
    "df_result = pd.DataFrame(result, columns=[\"Tag\", \"Sentence\"])\n",
    "\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59026e5",
   "metadata": {},
   "source": [
    "## Word Frequency Analysis Before meeting 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84c012c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('says', 462), ('herb', 270), ('lyle', 258), ('people', 172), ('board', 136), ('ralph', 130), ('ó', 127), ('wants', 125), ('tove', 120), ('swisher', 111)]\n",
      "Most common bigrams: [(('herb', 'says'), 55), (('lyle', 'says'), 35), (('million', 'dollars'), 34), (('bob', 'fulton'), 33), (('ralph', 'says'), 27), (('swisher', 'says'), 25), (('tove', 'says'), 24), (('wants', 'know'), 20), (('dick', 'clark'), 19), (('says', 'wants'), 17)]\n"
     ]
    }
   ],
   "source": [
    "from nltk import download\n",
    "\n",
    "# Ensure necessary NLTK resources are downloaded\n",
    "download('punkt', quiet=True)\n",
    "download('stopwords', quiet=True)\n",
    "\n",
    "# Function to clean and tokenize sentences\n",
    "def clean_and_tokenize(sentence):\n",
    "    if pd.isnull(sentence):\n",
    "        return []\n",
    "    \n",
    "    sentence = re.sub(r'\\W+', ' ', str(sentence)).lower()\n",
    "    words = word_tokenize(sentence)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in words if word.isalpha() and word not in stop_words]\n",
    "\n",
    "# Lists to store preceding sentences and tags\n",
    "preceding_sentences = []\n",
    "preceding_tags = []\n",
    "\n",
    "# Iterate through the DataFrame\n",
    "for index, row in df_result.iterrows():\n",
    "    if '4h' in row['Tag']:\n",
    "        # Get up to 3 preceding sentences and tags\n",
    "        for i in range(max(0, index-3), index):\n",
    "            preceding_sentences.append(df_result.iloc[i]['Sentence'])\n",
    "            preceding_tags.append(df_result.iloc[i]['Tag'])\n",
    "\n",
    "# List comprehension to tokenize and clean all preceding sentences\n",
    "all_words = [word for sentence in preceding_sentences for word in clean_and_tokenize(sentence)]\n",
    "\n",
    "# Calculate frequency distribution of words\n",
    "word_freq = FreqDist(all_words)\n",
    "print(\"Most common words:\", word_freq.most_common(10))\n",
    "\n",
    "# Generate bigrams from the list of words\n",
    "bigrams = ngrams(all_words, 2)\n",
    "\n",
    "# Calculate frequency distribution of bigrams\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "print(\"Most common bigrams:\", bigram_freq.most_common(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daf0eb7",
   "metadata": {},
   "source": [
    "## Tag Sequence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aba0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common third component sequences: [('4h -> 4h -> 4h', 20), ('4d -> 1b -> 4d', 11), ('4h -> 4d -> 4h', 10), ('4d -> 4d -> 4h', 9), ('1b -> 4d -> 1b', 9), ('1b -> 1c -> 1b', 9), ('1c -> 1b -> 1c', 9), ('4d -> 4d -> 4d', 9), ('1b -> 1c -> 4d', 8), ('4d -> 1c -> 4d', 8)]\n"
     ]
    }
   ],
   "source": [
    "def extract_third_component(tag):\n",
    "    match = re.findall(r'\\[c:\\d+,\\d+,(\\w+),\\d+\\]', tag)\n",
    "    if match:\n",
    "        return match[0]\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "def analyze_third_component_sequences(df):\n",
    "    preceding_tags = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if '4h' in row['Tag']:\n",
    "            # Get up to 3 preceding tags\n",
    "            start_index = max(0, index - 3)\n",
    "            for i in range(start_index, index):\n",
    "                tag = df.iloc[i]['Tag']\n",
    "                third_component = extract_third_component(tag)\n",
    "                if third_component:\n",
    "                    preceding_tags.append(third_component)\n",
    "\n",
    "    third_component_seq = [\" -> \".join(preceding_tags[i:i+3]) for i in range(len(preceding_tags) - 2)]\n",
    "    third_component_seq_freq = Counter(third_component_seq)\n",
    "\n",
    "    return third_component_seq_freq\n",
    "\n",
    "# Analyzing third component sequences\n",
    "third_component_seq_freq = analyze_third_component_sequences(df_result)\n",
    "\n",
    "# Display most common third component sequences\n",
    "print(\"Most common third component sequences:\", third_component_seq_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebba28",
   "metadata": {},
   "source": [
    "# Get 5 tags and sentences before meeting 4h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6983c524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[c:08,01,4e1,04]</td>\n",
       "      <td>Swisher would like to be able to assure the of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c:09,15,1a,04]</td>\n",
       "      <td>it was moved by Mr. Fulton,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[c:10,12,2a,04]</td>\n",
       "      <td>seconded by Mrs. Hammer, and unanimously carri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[c:11,15,1a,01]</td>\n",
       "      <td>It was moved by Mr. Fulton,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[c:12,11,2a,01]</td>\n",
       "      <td>seconded by Mr. Helstein, and unanimously carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>[c:97,22,4f,03]</td>\n",
       "      <td>Then comes LaverneÕs proposal for Reorganization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>[c:98,22,4e3,04]</td>\n",
       "      <td>which includes Walker, who is an old CEO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>[c:99,12,1c,04]</td>\n",
       "      <td>I ask if he wasn't the one who was fired and w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>[c:100,22,1b,04]</td>\n",
       "      <td>Laverne says he wasnÕt fired,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>[c:101,25,4h,04]</td>\n",
       "      <td>but Lyle says, \"Yes, he was fired.Ó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1376 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Tag                                           Sentence\n",
       "0     [c:08,01,4e1,04]  Swisher would like to be able to assure the of...\n",
       "1      [c:09,15,1a,04]                        it was moved by Mr. Fulton,\n",
       "2      [c:10,12,2a,04]  seconded by Mrs. Hammer, and unanimously carri...\n",
       "3      [c:11,15,1a,01]                        It was moved by Mr. Fulton,\n",
       "4      [c:12,11,2a,01]  seconded by Mr. Helstein, and unanimously carr...\n",
       "...                ...                                                ...\n",
       "1371   [c:97,22,4f,03]   Then comes LaverneÕs proposal for Reorganization\n",
       "1372  [c:98,22,4e3,04]          which includes Walker, who is an old CEO.\n",
       "1373   [c:99,12,1c,04]  I ask if he wasn't the one who was fired and w...\n",
       "1374  [c:100,22,1b,04]                      Laverne says he wasnÕt fired,\n",
       "1375  [c:101,25,4h,04]                but Lyle says, \"Yes, he was fired.Ó\n",
       "\n",
       "[1376 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_sentences_with_4h_and_preceding(df, target_component='4h', num_previous=5):\n",
    "    df['ThirdComponent'] = df['Tag'].apply(lambda x: x.split(',')[2])\n",
    "\n",
    "    included_sentences = set()\n",
    "    result = []\n",
    "\n",
    "    for index in range(len(df)):\n",
    "        if df.iloc[index]['ThirdComponent'] == target_component:\n",
    "            # Determine the range of indices to include\n",
    "            start_index = max(index - num_previous, 0)\n",
    "            end_index = index + 1  # Include current index\n",
    "\n",
    "            for idx in range(start_index, end_index):\n",
    "                # Check to avoid duplicates\n",
    "                if df.iloc[idx]['Sentence'] not in included_sentences:\n",
    "                    result.append(df.iloc[idx][['Tag', 'Sentence']].tolist())\n",
    "                    included_sentences.add(df.iloc[idx]['Sentence'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "result = find_sentences_with_4h_and_preceding(df)\n",
    "df_result_5 = pd.DataFrame(result, columns=[\"Tag\", \"Sentence\"])\n",
    "df_result_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60d83e0",
   "metadata": {},
   "source": [
    "## Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f20871ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words: [('says', 463), ('herb', 264), ('lyle', 250), ('people', 171), ('board', 137), ('ralph', 128), ('wants', 126), ('tove', 115), ('swisher', 108), ('get', 103)]\n",
      "Most common bigrams: [(('herb', 'says'), 55), (('lyle', 'says'), 35), (('million', 'dollars'), 34), (('bob', 'fulton'), 32), (('ralph', 'says'), 27), (('swisher', 'says'), 25), (('tove', 'says'), 24), (('wants', 'know'), 20), (('dick', 'clark'), 18), (('says', 'wants'), 17)]\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources quietly\n",
    "download('punkt', quiet=True)\n",
    "download('stopwords', quiet=True)\n",
    "\n",
    "# Improved tokenizer\n",
    "tokenizer = RegexpTokenizer(r\"\\b\\w[\\w']+\\b\")\n",
    "\n",
    "# Use NLTK's stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_and_tokenize(sentence):\n",
    "    if pd.isnull(sentence):\n",
    "        return []\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    words = tokenizer.tokenize(sentence)\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "# Assuming df_result_5 is your DataFrame\n",
    "# Extract preceding sentences\n",
    "preceding_sentences = [df_result_5.iloc[i]['Sentence'] for index, row in df_result_5.iterrows() if '4h' in row['Tag'] for i in range(max(0, index-3), index)]\n",
    "\n",
    "# Word Frequency Analysis\n",
    "all_words = [word for sentence in preceding_sentences for word in clean_and_tokenize(sentence)]\n",
    "word_freq = FreqDist(all_words)\n",
    "\n",
    "# Display most common words\n",
    "print(\"Most common words:\", word_freq.most_common(10))\n",
    "\n",
    "# N-gram Analysis\n",
    "bigrams = ngrams(all_words, 2)\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "print(\"Most common bigrams:\", bigram_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf54873",
   "metadata": {},
   "source": [
    "## Tag Sequence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3fb864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4h -> 4h -> 4h -> 4h -> 4h', 7),\n",
       " ('4d -> 4d -> 4d -> 4d -> 4d', 5),\n",
       " ('1b -> 1b -> 4d -> 1c -> 4d', 3),\n",
       " ('4h -> 4d -> 4h -> 4d -> 4h', 3),\n",
       " ('4d -> 1b -> 1b -> 1b -> 4d', 3),\n",
       " ('1b -> 1c -> 1b -> 1c -> 1b', 3),\n",
       " ('1c -> 1b -> 1c -> 1b -> 1c', 3),\n",
       " ('1b -> 4d -> 1b -> 1b -> 1b', 3),\n",
       " ('1b -> 4h -> 1b -> 4d -> 1c', 2),\n",
       " ('4h -> 1b -> 4d -> 1c -> 1b', 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_third_component(tag):\n",
    "    match = re.findall(r'\\[c:\\d+,\\d+,(\\w+),\\d+\\]', tag)\n",
    "    return match[0] if match else None\n",
    "\n",
    "def analyze_third_component_sequences_with_five(df):\n",
    "    preceding_tags = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if '4h' in row['Tag']:\n",
    "            # Get up to 5 preceding tags\n",
    "            start_index = max(0, index - 5)\n",
    "            for i in range(start_index, index):\n",
    "                tag = df.iloc[i]['Tag']\n",
    "                third_component = extract_third_component(tag)\n",
    "                if third_component:\n",
    "                    preceding_tags.append(third_component)\n",
    "\n",
    "    # Create sequences of 5 third components\n",
    "    third_component_seq = [\" -> \".join(preceding_tags[i:i+5]) for i in range(len(preceding_tags) - 4)]\n",
    "    third_component_seq_freq = Counter(third_component_seq)\n",
    "\n",
    "    return third_component_seq_freq\n",
    "\n",
    "# Analyzing third component sequences\n",
    "third_component_seq_freq = analyze_third_component_sequences_with_five(df_result_5)\n",
    "\n",
    "# Display most common third component sequences\n",
    "most_common_sequences = third_component_seq_freq.most_common(10)\n",
    "most_common_sequences\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "177.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
